spark-bench = {
  spark-submit-config = [{
    spark-home = "/home/ikt/spark-2.2.1/" // PATH TO YOUR SPARK INSTALLATION
    spark-args = {
      master = "spark://172.23.27.10:7077" // FILL IN YOUR MASTER HERE
      executor-memory = "20g" // FILL IN YOUR EXECUTOR MEMORY
    }
    conf = {
      // Any configuration you need for your setup goes here, like:
      // "spark.dynamicAllocation.enabled" = "false"
    }
    suites-parallel = false
    workload-suites = [
      {
        descr = "Generate a dataset, then take that same dataset and write it o$
        benchmark-output = "hdfs:///tmp/csv-vs-parquet/results-data-gen.csv"
        // We need to generate the dataset first through the data generator, th$
        parallel = false
        workloads = [
          {
            name = "data-generation-kmeans"
            rows = 10000000
            cols = 24
            output = "hdfs://172.23.27.20:9000/tmp/csv-vs-parquet/kmeans-data.c$
          },
          {
            name = "sql"
            query = "select * from input"
            input = "hdfs://172.23.27.20:9000/tmp/csv-vs-parquet/kmeans-data.cs$
            output = "hdfs://172.23.27.20:9000/tmp/csv-vs-parquet/kmeans-data.p$
          }
        ]
      },
      {
        descr = "Run two different SQL queries over the dataset in two differen$
        benchmark-output = "hdfs://172.23.27.20:9000/tmp/csv-vs-parquet/results$
        parallel = false
        repeat = 10
        workloads = [
          {
            name = "sql"
            input = ["hdfs://172.23.27.20:9000/tmp/csv-vs-parquet/kmeans-data.c$
            query = ["select * from input", "select `0`, `22` from input where $
            cache = false
          }
        ]
      }
    ]
  }]
}

